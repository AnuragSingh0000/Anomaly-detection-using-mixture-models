{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_vqvae.py\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf\n",
    "\n",
    "from forward_step import ComputeLossVQVAE\n",
    "from model import DAGMM_VQVAE\n",
    "\n",
    "\n",
    "def eval(args, model, dataloaders, device, sub=20):\n",
    "    \"\"\"Evaluate the DAGMM‑VQ‑VAE model with GMM energy scoring.\"\"\"\n",
    "    train_loader, test_loader = dataloaders\n",
    "    model.eval()\n",
    "    print('Evaluating DAGMM‑VQ‑VAE...')\n",
    "\n",
    "    # Use ComputeLossVQVAE only for its compute_params and compute_energy\n",
    "    compute = ComputeLossVQVAE(\n",
    "        lambda_energy=args.lambda_energy,\n",
    "        lambda_cov=args.lambda_cov,\n",
    "        device=device,\n",
    "        n_gmm=args.n_gmm\n",
    "    )\n",
    "\n",
    "    # 1) Estimate GMM parameters on training (clean) data\n",
    "    with torch.no_grad():\n",
    "        N = 0\n",
    "        gamma_sum = 0\n",
    "        mu_sum    = 0\n",
    "        cov_sum   = 0\n",
    "\n",
    "        for x, _ in train_loader:\n",
    "            x = x.float().to(device)\n",
    "            out = model(x)\n",
    "            z_q   = out['z_q']\n",
    "            gamma = out['gamma']\n",
    "\n",
    "            phi_batch, mu_batch, cov_batch = compute.compute_params(z_q, gamma)\n",
    "            batch_gamma_sum = gamma.sum(dim=0)\n",
    "\n",
    "            gamma_sum += batch_gamma_sum\n",
    "            mu_sum    += mu_batch * batch_gamma_sum.unsqueeze(-1)\n",
    "            cov_sum   += cov_batch * batch_gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "            N        += x.size(0)\n",
    "\n",
    "        phi = gamma_sum / N\n",
    "        mu  = mu_sum    / gamma_sum.unsqueeze(-1)\n",
    "        cov = cov_sum   / gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "    # 2) Compute energy scores for train and test\n",
    "    def get_scores(loader):\n",
    "        scores, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x = x.float().to(device)\n",
    "                out = model(x)\n",
    "                z_q   = out['z_q']\n",
    "                gamma = out['gamma']\n",
    "\n",
    "                energy, _ = compute.compute_energy(\n",
    "                    z_q, gamma,\n",
    "                    phi=phi, mu=mu, cov=cov,\n",
    "                    sample_mean=False\n",
    "                )\n",
    "                scores.append(energy.cpu())\n",
    "                labels.append(y)\n",
    "        return torch.cat(scores).numpy(), torch.cat(labels).numpy()\n",
    "\n",
    "    energy_train, labels_train = get_scores(train_loader)\n",
    "    energy_test,  labels_test  = get_scores(test_loader)\n",
    "\n",
    "    # Combine for threshold and AUC\n",
    "    all_scores = np.concatenate([energy_train, energy_test])\n",
    "    all_labels = np.concatenate([labels_train,  labels_test])\n",
    "\n",
    "    # Set threshold (e.g., top 20% anomalies)\n",
    "    thresh = np.percentile(all_scores, 100-sub)\n",
    "    print(f\"Threshold (top {sub}% of TRAIN): {thresh:.4f}\")\n",
    "\n",
    "    # 4) Predict & evaluate on TEST\n",
    "    preds = (energy_test > thresh).astype(int)\n",
    "    precision, recall, f1, _ = prf(labels_test, preds, average='binary', zero_division=0)\n",
    "    auc = roc_auc_score(labels_test, energy_test)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc*100:.2f}%\")\n",
    "\n",
    "    return labels_test, energy_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from preprocess import get_KDDCup99\n",
    "from train import TrainerDAGMMVQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Args:\n",
    "    num_epochs    = 100\n",
    "    patience      = 50\n",
    "    lr            = 1e-4\n",
    "    lr_milestones = [50]\n",
    "    batch_size    = 1024\n",
    "    latent_dim    = 1\n",
    "    n_gmm         = 4\n",
    "    num_embeddings= 16\n",
    "    lambda_energy = 0.1\n",
    "    lambda_cov    = 0.005\n",
    "\n",
    "args   = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data   = get_KDDCup99(args)\n",
    "\n",
    "trainer = TrainerDAGMMVQVAE(args, data, device)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sub in [10,20,30,40,50,60]:\n",
    "    print(f\"-- top {sub}% anomalies --\")\n",
    "    eval(args, trainer.model, data, device, sub=sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_inlier_outlier_kde(labels, scores, model_name='DAGMM', sub=None):\n",
    "    \"\"\"\n",
    "    Plot KDEs of inlier (label=0) vs outlier (label=1) score distributions.\n",
    "\n",
    "    Args:\n",
    "        labels (array-like): 0 for inliers, 1 for outliers\n",
    "        scores (array-like): anomaly scores\n",
    "        model_name (str): Used in the title\n",
    "        sub (int, optional): percentile threshold used, if any\n",
    "    \"\"\"\n",
    "    # Split scores\n",
    "    scores_in  = scores[np.where(labels == 0)[0]]\n",
    "    scores_out = scores[np.where(labels == 1)[0]]\n",
    "\n",
    "    # Make DataFrames\n",
    "    df_in  = pd.DataFrame(scores_in,  columns=['Inlier'])\n",
    "    df_out = pd.DataFrame(scores_out, columns=['Outlier'])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    df_in .plot.kde(ax=ax, legend=True)\n",
    "    df_out.plot.kde(ax=ax, legend=True)\n",
    "\n",
    "    # Title & grids\n",
    "    title = f'{model_name} Inlier vs Outlier KDE'\n",
    "    if sub is not None:\n",
    "        title += f' (top {sub}% threshold)'\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Anomaly Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vq, scores_vq = eval_vqvae(trainer.model, data, device, args.n_gmm, sub=30)\n",
    "plot_inlier_outlier_kde(labels_vq, scores_vq, model_name='DAGMM‑VQ‑VAE', sub=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
